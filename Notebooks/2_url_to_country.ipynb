{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c943d67-7d6d-4e21-b54f-a0684c2446ae",
   "metadata": {},
   "source": [
    "# Find Country name from the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0bc996c-80d2-444c-ab7e-850bb6c38efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tldextract\n",
      "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from tldextract) (3.7)\n",
      "Requirement already satisfied: requests>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from tldextract) (2.31.0)\n",
      "Collecting requests-file>=1.4 (from tldextract)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting filelock>=3.0.8 (from tldextract)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.1.0->tldextract) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.1.0->tldextract) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.1.0->tldextract) (2024.2.2)\n",
      "Downloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Installing collected packages: filelock, requests-file, tldextract\n",
      "Successfully installed filelock-3.18.0 requests-file-2.1.0 tldextract-5.3.0\n",
      "Collecting geoip2\n",
      "  Downloading geoip2-5.0.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.6.2 (from geoip2)\n",
      "  Downloading aiohttp-3.11.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting maxminddb<3.0.0,>=2.5.1 (from geoip2)\n",
      "  Downloading maxminddb-2.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.11/site-packages (from geoip2) (2.31.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.6.2->geoip2)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.6.2->geoip2)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.6.2->geoip2)\n",
      "  Downloading frozenlist-1.6.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.6.2->geoip2)\n",
      "  Downloading multidict-6.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.6.2->geoip2)\n",
      "  Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.6.2->geoip2)\n",
      "  Downloading yarl-1.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m879.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->geoip2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->geoip2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->geoip2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->geoip2) (2024.2.2)\n",
      "Downloading geoip2-5.0.1-py3-none-any.whl (28 kB)\n",
      "Downloading aiohttp-3.11.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading maxminddb-2.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/88.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.5/223.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.5/232.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.1/358.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: propcache, multidict, maxminddb, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, geoip2\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 frozenlist-1.6.0 geoip2-5.0.1 maxminddb-2.6.3 multidict-6.4.3 propcache-0.3.1 yarl-1.20.0\n",
      "Collecting pycountry\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pycountry\n",
      "Successfully installed pycountry-24.6.1\n",
      "Collecting python-whois\n",
      "  Downloading python_whois-0.9.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.11/site-packages (from python-whois) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil->python-whois) (1.16.0)\n",
      "Downloading python_whois-0.9.5-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.2/104.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-whois\n",
      "Successfully installed python-whois-0.9.5\n"
     ]
    }
   ],
   "source": [
    "!pip install tldextract\n",
    "!pip install geoip2\n",
    "!pip install pycountry\n",
    "!pip install python-whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f704a207-9847-4318-8314-5fceb199f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 url        country\n",
      "0                             https://www.lemonde.fr         France\n",
      "1                         https://www.bbc.co.uk/news  United States\n",
      "2                            https://www.nytimes.com  United States\n",
      "3                                https://example.org  United States\n",
      "4  https://www.stabroeknews.com/2025/01/05/news/g...         Guyana\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tldextract\n",
    "import socket\n",
    "import geoip2.database\n",
    "import pycountry\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "# 1) Load your GeoLite2 database\n",
    "GEOIP_DB_PATH = \"GeoLite2-Country.mmdb\"\n",
    "geo_reader   = geoip2.database.Reader(GEOIP_DB_PATH)\n",
    "\n",
    "def country_from_ip(url):\n",
    "    ext    = tldextract.extract(url)\n",
    "    domain = f\"{ext.domain}.{ext.suffix}\"\n",
    "    try:\n",
    "        ip   = socket.gethostbyname(domain)\n",
    "        resp = geo_reader.country(ip)\n",
    "        return resp.country.name\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def country_from_tld(url):\n",
    "    ext    = tldextract.extract(url)\n",
    "    code   = ext.suffix.lower().split('.')[-1]\n",
    "    if len(code) == 2:\n",
    "        if code == 'uk':   # normalize UK→GB\n",
    "            code = 'gb'\n",
    "        country = pycountry.countries.get(alpha_2=code.upper())\n",
    "        if country:\n",
    "            return country.name\n",
    "    return None\n",
    "\n",
    "def country_from_path(url):\n",
    "    \"\"\"\n",
    "    Exact match on each path token (and sub-token split on - or _).\n",
    "    This avoids ‘news’ → Sweden, but will catch ‘guyana’.\n",
    "    \"\"\"\n",
    "    path = urlparse(url).path.strip('/')\n",
    "    for segment in path.split('/'):\n",
    "        for token in re.split(r'[-_]', segment):\n",
    "            if not token:\n",
    "                continue\n",
    "            try:\n",
    "                # lookup() matches alpha_2, alpha_3, or exact country name (case-insensitive)\n",
    "                return pycountry.countries.lookup(token).name\n",
    "            except LookupError:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "def detect_country(url):\n",
    "    # 1) Hosting‐location via GeoIP\n",
    "    c = country_from_ip(url)\n",
    "    if c:\n",
    "        return c\n",
    "\n",
    "    # 2) ccTLD hint\n",
    "    c = country_from_tld(url)\n",
    "    if c:\n",
    "        return c\n",
    "\n",
    "    # 3) URL‐path fallback\n",
    "    return country_from_path(url)\n",
    "\n",
    "# Example\n",
    "df = pd.DataFrame({\n",
    "    \"url\": [\n",
    "        \"https://www.lemonde.fr\",\n",
    "        \"https://www.bbc.co.uk/news\",\n",
    "        \"https://www.nytimes.com\",\n",
    "        \"https://example.org\",\n",
    "        \"https://www.stabroeknews.com/2025/01/05/news/guyana/hamas-and-israel-edge-towards-ceasefire\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "df[\"country\"] = df[\"url\"].apply(detect_country)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b23d154-f857-4ac1-9a61-9a9ce0cc2159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           SOURCEURL         country\n",
      "0                             https://www.lemonde.fr          France\n",
      "1                         https://www.bbc.co.uk/news  United Kingdom\n",
      "2                            https://www.nytimes.com   United States\n",
      "3                                https://example.org   United States\n",
      "4  https://www.stabroeknews.com/2025/01/05/news/g...          Guyana\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tldextract\n",
    "import socket\n",
    "import geoip2.database\n",
    "import pycountry\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "GEOIP_DB_PATH = \"GeoLite2-Country.mmdb\"\n",
    "geo_reader = geoip2.database.Reader(GEOIP_DB_PATH)\n",
    "\n",
    "def country_from_tld(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    suffix_parts = ext.suffix.split('.')\n",
    "    # Check all parts of the suffix for a valid ccTLD (e.g., 'co.uk' → 'uk')\n",
    "    for part in reversed(suffix_parts):\n",
    "        if len(part) == 2:\n",
    "            code = part.lower()\n",
    "            if code == 'uk':\n",
    "                code = 'gb'  # pycountry uses 'GB' for United Kingdom\n",
    "            country = pycountry.countries.get(alpha_2=code.upper())\n",
    "            if country:\n",
    "                return country.name\n",
    "    return None\n",
    "\n",
    "def country_from_ip(url):\n",
    "    try:\n",
    "        domain = tldextract.extract(url).top_domain_under_public_suffix  # New\n",
    "        if not domain:\n",
    "            return None\n",
    "        ip = socket.gethostbyname(domain)\n",
    "        resp = geo_reader.country(ip)\n",
    "        return resp.country.name\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def country_from_path(url):\n",
    "    country_names = {country.name.lower(): country.name for country in pycountry.countries}\n",
    "    path_segments = urlparse(url).path.strip('/').split('/')\n",
    "    for segment in path_segments:\n",
    "        for token in re.split(r'[-_+]', segment):\n",
    "            token_lower = token.lower()\n",
    "            if token_lower in country_names:\n",
    "                return country_names[token_lower]\n",
    "    return None\n",
    "\n",
    "def detect_country(url):\n",
    "    # 1) Check TLD first\n",
    "    country = country_from_tld(url)\n",
    "    if country:\n",
    "        return country\n",
    "    \n",
    "    # 2) Fallback to GeoIP\n",
    "    country = country_from_ip(url)\n",
    "    if country:\n",
    "        return country\n",
    "    \n",
    "    # 3) Check URL path for country names\n",
    "    return country_from_path(url)\n",
    "\n",
    "# Example Usage\n",
    "df = pd.DataFrame({\n",
    "    \"SOURCEURL\": [\n",
    "        \"https://www.lemonde.fr\",\n",
    "        \"https://www.bbc.co.uk/news\",\n",
    "        \"https://www.nytimes.com\",\n",
    "        \"https://example.org\",\n",
    "        \"https://www.stabroeknews.com/2025/01/05/news/guyana/hamas-and-israel-edge-towards-ceasefire\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "df[\"country\"] = df[\"SOURCEURL\"].apply(detect_country)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d204683-f878-408c-8100-da70e8a25afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.0%\n",
      "\n",
      "Detailed Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCEURL</th>\n",
       "      <th>Actual Country</th>\n",
       "      <th>Predicted Country</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.bbc.com</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.nytimes.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.theguardian.com</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.lemonde.fr</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.spiegel.de</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.repubblica.it</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Italy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.elpais.com</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.globo.com</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.japantimes.co.jp</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Japan</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.timesofindia.com</td>\n",
       "      <td>India</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.scmp.com</td>\n",
       "      <td>China</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.haaretz.com</td>\n",
       "      <td>Israel</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.rt.com</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.aljazeera.com</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.straitstimes.com</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.smh.com.au</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.thestar.com.my</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.torontostar.ca</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.chinadaily.com.cn</td>\n",
       "      <td>China</td>\n",
       "      <td>China</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.dawn.com</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        SOURCEURL  Actual Country Predicted Country  Match\n",
       "0             https://www.bbc.com  United Kingdom     United States  False\n",
       "1         https://www.nytimes.com   United States     United States   True\n",
       "2     https://www.theguardian.com  United Kingdom     United States  False\n",
       "3          https://www.lemonde.fr          France            France   True\n",
       "4          https://www.spiegel.de         Germany           Germany   True\n",
       "5       https://www.repubblica.it           Italy             Italy   True\n",
       "6          https://www.elpais.com           Spain            Sweden  False\n",
       "7           https://www.globo.com          Brazil            Brazil   True\n",
       "8    https://www.japantimes.co.jp           Japan             Japan   True\n",
       "9    https://www.timesofindia.com           India            Sweden  False\n",
       "10           https://www.scmp.com           China              None  False\n",
       "11        https://www.haaretz.com          Israel     United States  False\n",
       "12             https://www.rt.com          Russia            Russia   True\n",
       "13      https://www.aljazeera.com           Qatar            Sweden  False\n",
       "14   https://www.straitstimes.com       Singapore     United States  False\n",
       "15         https://www.smh.com.au       Australia         Australia   True\n",
       "16     https://www.thestar.com.my        Malaysia          Malaysia   True\n",
       "17     https://www.torontostar.ca          Canada            Canada   True\n",
       "18  https://www.chinadaily.com.cn           China             China   True\n",
       "19           https://www.dawn.com        Pakistan              None  False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset of major news websites with actual countries\n",
    "data = {\n",
    "    \"SOURCEURL\": [\n",
    "        \"https://www.bbc.com\",           # UK\n",
    "        \"https://www.nytimes.com\",        # USA\n",
    "        \"https://www.theguardian.com\",    # UK\n",
    "        \"https://www.lemonde.fr\",         # France\n",
    "        \"https://www.spiegel.de\",         # Germany\n",
    "        \"https://www.repubblica.it\",      # Italy\n",
    "        \"https://www.elpais.com\",         # Spain\n",
    "        \"https://www.globo.com\",          # Brazil\n",
    "        \"https://www.japantimes.co.jp\",   # Japan\n",
    "        \"https://www.timesofindia.com\",   # India\n",
    "        \"https://www.scmp.com\",           # Hong Kong\n",
    "        \"https://www.haaretz.com\",        # Israel\n",
    "        \"https://www.rt.com\",             # Russia\n",
    "        \"https://www.aljazeera.com\",      # Qatar\n",
    "        \"https://www.straitstimes.com\",   # Singapore\n",
    "        \"https://www.smh.com.au\",         # Australia\n",
    "        \"https://www.thestar.com.my\",     # Malaysia\n",
    "        \"https://www.torontostar.ca\",     # Canada\n",
    "        \"https://www.chinadaily.com.cn\",  # China\n",
    "        \"https://www.dawn.com\",           # Pakistan\n",
    "    ],\n",
    "    \"Actual Country\": [\n",
    "        \"United Kingdom\", \"United States\", \"United Kingdom\", \"France\", \"Germany\",\n",
    "        \"Italy\", \"Spain\", \"Brazil\", \"Japan\", \"India\", \"China\", \"Israel\", \"Russia\",\n",
    "        \"Qatar\", \"Singapore\", \"Australia\", \"Malaysia\", \"Canada\", \"China\", \"Pakistan\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the detection algorithm\n",
    "df[\"Predicted Country\"] = df[\"SOURCEURL\"].apply(detect_country)\n",
    "\n",
    "# Compare results\n",
    "df[\"Match\"] = df[\"Actual Country\"] == df[\"Predicted Country\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = df[\"Match\"].mean()\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.1%}\")\n",
    "print(\"\\nDetailed Results:\")\n",
    "df[[\"SOURCEURL\", \"Actual Country\", \"Predicted Country\", \"Match\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
