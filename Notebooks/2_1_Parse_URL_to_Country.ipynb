{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c688c39-e79a-43c0-906f-4da39d10a56c",
   "metadata": {},
   "source": [
    "## Define the list of the 50 most popular news sites and their source countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ef03c7e-ee71-400c-b708-f71abab3c462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://cnn.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://bbc.co.uk</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://bloomberg.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://nytimes.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://washingtonpost.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://theguardian.com</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://foxnews.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://nbcnews.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://cnbc.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://reuters.com</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          url         country\n",
       "0             https://cnn.com   United States\n",
       "1           https://bbc.co.uk  United Kingdom\n",
       "2       https://bloomberg.com   United States\n",
       "3         https://nytimes.com   United States\n",
       "4  https://washingtonpost.com   United States\n",
       "5     https://theguardian.com  United Kingdom\n",
       "6         https://foxnews.com   United States\n",
       "7         https://nbcnews.com   United States\n",
       "8            https://cnbc.com   United States\n",
       "9         https://reuters.com  United Kingdom"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "news_data = [\n",
    "    # Original Entries (50)\n",
    "    {\"url\": \"https://cnn.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://bbc.co.uk\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://bloomberg.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://nytimes.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://washingtonpost.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://theguardian.com\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://foxnews.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://nbcnews.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://cnbc.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://reuters.com\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://forbes.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://huffpost.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://politico.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://wsj.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://time.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://usatoday.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://dailymail.co.uk\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://thetimes.co.uk\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://thesun.co.uk\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://telegraph.co.uk\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://mirror.co.uk\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://express.co.uk\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://independent.co.uk\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://nypost.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://latimes.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://usnews.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://axios.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://buzzfeednews.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://vice.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://aljazeera.com\", \"country\": \"Qatar\"},\n",
    "    {\"url\": \"https://euronews.com\", \"country\": \"France\"},\n",
    "    {\"url\": \"https://lemonde.fr\", \"country\": \"France\"},\n",
    "    {\"url\": \"https://elpais.com\", \"country\": \"Spain\"},\n",
    "    {\"url\": \"https://spiegel.de\", \"country\": \"Germany\"},\n",
    "    {\"url\": \"https://lefigaro.fr\", \"country\": \"France\"},\n",
    "    {\"url\": \"https://corriere.it\", \"country\": \"Italy\"},\n",
    "    {\"url\": \"https://repubblica.it\", \"country\": \"Italy\"},\n",
    "    {\"url\": \"https://eluniversal.com.mx\", \"country\": \"Mexico\"},\n",
    "    {\"url\": \"https://ouest-france.fr\", \"country\": \"France\"},\n",
    "    {\"url\": \"https://asahi.com\", \"country\": \"Japan\"},\n",
    "    {\"url\": \"https://scmp.com\", \"country\": \"Hong Kong\"},\n",
    "    {\"url\": \"https://chinadaily.com.cn\", \"country\": \"China\"},\n",
    "    {\"url\": \"https://straitstimes.com\", \"country\": \"Singapore\"},\n",
    "    {\"url\": \"https://thehindu.com\", \"country\": \"India\"},\n",
    "    {\"url\": \"https://hindustantimes.com\", \"country\": \"India\"},\n",
    "    {\"url\": \"https://timesofindia.indiatimes.com\", \"country\": \"India\"},\n",
    "    {\"url\": \"https://dawn.com\", \"country\": \"Pakistan\"},\n",
    "    {\"url\": \"https://arabnews.com\", \"country\": \"Saudi Arabia\"},\n",
    "    {\"url\": \"https://thejakartapost.com\", \"country\": \"Indonesia\"},\n",
    "    {\"url\": \"https://rt.com\", \"country\": \"Russia\"},\n",
    "\n",
    "    # New Additions (50)\n",
    "    {\"url\": \"https://thehill.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://businessinsider.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://chicagotribune.com\", \"country\": \"United States\"},\n",
    "    {\"url\": \"https://theglobeandmail.com\", \"country\": \"Canada\"},\n",
    "    {\"url\": \"https://cbc.ca\", \"country\": \"Canada\"},\n",
    "    {\"url\": \"https://thestar.com\", \"country\": \"Canada\"},\n",
    "    {\"url\": \"https://economist.com\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://standard.co.uk\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://metro.co.uk\", \"country\": \"United Kingdom\"},\n",
    "    {\"url\": \"https://liberation.fr\", \"country\": \"France\"},\n",
    "    {\"url\": \"https://lequipe.fr\", \"country\": \"France\"},\n",
    "    {\"url\": \"https://france24.com\", \"country\": \"France\"},\n",
    "    {\"url\": \"https://bild.de\", \"country\": \"Germany\"},\n",
    "    {\"url\": \"https://dw.com\", \"country\": \"Germany\"},\n",
    "    {\"url\": \"https://faz.net\", \"country\": \"Germany\"},\n",
    "    {\"url\": \"https://elmundo.es\", \"country\": \"Spain\"},\n",
    "    {\"url\": \"https://abc.es\", \"country\": \"Spain\"},\n",
    "    {\"url\": \"https://lastampa.it\", \"country\": \"Italy\"},\n",
    "    {\"url\": \"https://mainichi.jp\", \"country\": \"Japan\"},\n",
    "    {\"url\": \"https://asia.nikkei.com\", \"country\": \"Japan\"},\n",
    "    {\"url\": \"https://yna.co.kr\", \"country\": \"South Korea\"},\n",
    "    {\"url\": \"https://koreaherald.com\", \"country\": \"South Korea\"},\n",
    "    {\"url\": \"https://smh.com.au\", \"country\": \"Australia\"},\n",
    "    {\"url\": \"https://theaustralian.com.au\", \"country\": \"Australia\"},\n",
    "    {\"url\": \"https://indianexpress.com\", \"country\": \"India\"},\n",
    "    {\"url\": \"https://deccanherald.com\", \"country\": \"India\"},\n",
    "    {\"url\": \"https://haaretz.com\", \"country\": \"Israel\"},\n",
    "    {\"url\": \"https://thenationalnews.com\", \"country\": \"United Arab Emirates\"},\n",
    "    {\"url\": \"https://gulfnews.com\", \"country\": \"United Arab Emirates\"},\n",
    "    {\"url\": \"https://mg.co.za\", \"country\": \"South Africa\"},\n",
    "    {\"url\": \"https://english.ahram.org.eg\", \"country\": \"Egypt\"},\n",
    "    {\"url\": \"https://punchng.com\", \"country\": \"Nigeria\"},\n",
    "    {\"url\": \"https://oglobo.globo.com\", \"country\": \"Brazil\"},\n",
    "    {\"url\": \"https://clarin.com\", \"country\": \"Argentina\"},\n",
    "    {\"url\": \"https://elcomercio.pe\", \"country\": \"Peru\"},\n",
    "    {\"url\": \"https://emol.com\", \"country\": \"Chile\"},\n",
    "    {\"url\": \"https://nzz.ch\", \"country\": \"Switzerland\"},\n",
    "    {\"url\": \"https://derstandard.at\", \"country\": \"Austria\"},\n",
    "    {\"url\": \"https://wyborcza.pl\", \"country\": \"Poland\"},\n",
    "    {\"url\": \"https://bangkokpost.com\", \"country\": \"Thailand\"},\n",
    "    {\"url\": \"https://mb.com.ph\", \"country\": \"Philippines\"},\n",
    "    {\"url\": \"https://thestar.com.my\", \"country\": \"Malaysia\"},\n",
    "    {\"url\": \"https://cgtn.com\", \"country\": \"China\"},\n",
    "    {\"url\": \"https://tass.com\", \"country\": \"Russia\"},\n",
    "    {\"url\": \"https://aa.com.tr\", \"country\": \"Turkey\"},\n",
    "    {\"url\": \"https://aftenposten.no\", \"country\": \"Norway\"},\n",
    "    {\"url\": \"https://hs.fi\", \"country\": \"Finland\"},\n",
    "    {\"url\": \"https://berlingske.dk\", \"country\": \"Denmark\"},\n",
    "    {\"url\": \"https://kathimerini.gr\", \"country\": \"Greece\"},\n",
    "    {\"url\": \"https://hurriyet.com.tr\", \"country\": \"Turkey\"}\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "news_df = pd.DataFrame(news_data)\n",
    "\n",
    "# Display to the user\n",
    "news_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66eb616-10e4-49a6-8ba5-818a3263c322",
   "metadata": {},
   "source": [
    "## Download the dataset for news outlet and their corresponding country.\n",
    "[dataset's web page link](https://blog.gdeltproject.org/mapping-the-media-a-geographic-lookup-of-gdelts-sources/)\n",
    "\n",
    "[dataset link](http://data.gdeltproject.org/blog/2018-news-outlets-by-country-may2018-update/MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018.TXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2861dce9-468e-4a8b-b628-229e2a08e2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 189,545 rows to MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) URL of the master TXT file\n",
    "url = \"http://data.gdeltproject.org/blog/2018-news-outlets-by-country-may2018-update/MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018.TXT\"\n",
    "\n",
    "# 2) Define column names (the file has three columns: domain, country code, country name)\n",
    "cols = [\"domain\", \"country_code\", \"country_name\"]\n",
    "\n",
    "# 3) Read directly from the URL as a TSV\n",
    "df = pd.read_csv(\n",
    "    url,\n",
    "    sep=\"\\t\",            # tab-separated\n",
    "    names=cols,          # assign our column names\n",
    "    header=None,         # no header row in the TXT\n",
    "    dtype=str,           # keep everything as strings\n",
    "    na_filter=False      # don’t convert empty strings to NaN\n",
    ")\n",
    "\n",
    "# 4) Write out to CSV (comma-separated)\n",
    "output_path = \"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Wrote {len(df):,} rows to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17499ee-aa58-4f4b-9519-542cdcd72022",
   "metadata": {},
   "source": [
    "## Check if there are any null values in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2488b593-89f2-43fb-a5ac-fa359452e0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'domain': null_or_nan = 0, empty_string = 0\n",
      "'country_code': null_or_nan = 0, empty_string = 0\n",
      "'country_name': null_or_nan = 15, empty_string = 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018.csv\", dtype=str)\n",
    "\n",
    "# Check each column\n",
    "for col in df.columns:\n",
    "    n_null   = df[col].isnull().sum()\n",
    "    n_empty  = (df[col] == \"\").sum()\n",
    "    print(f\"{col!r}: null_or_nan = {n_null}, empty_string = {n_empty}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "249cc2ce-50cd-49c6-aee2-453bc1990abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domains with missing country_name and their country_code:\n",
      "              domain country_code country_name\n",
      "   balkaninsight.com           RB          NaN\n",
      "       balkanist.net           RB          NaN\n",
      "      balkanrock.com           RB          NaN\n",
      "      glassrpske.com           RB          NaN\n",
      "learnserbianblog.com           RB          NaN\n",
      "       mcraeblog.com           RB          NaN\n",
      "       nezavisne.com           RB          NaN\n",
      "radiokontaktplus.org           RB          NaN\n",
      "             rtrs.tv           RB          NaN\n",
      "           rtvbn.com           RB          NaN\n",
      " stillinbelgrade.com           RB          NaN\n",
      "    streetart360.net           RB          NaN\n",
      "        svetplus.com           RB          NaN\n",
      "        urbanbug.net           RB          NaN\n",
      "       vukajlija.com           RB          NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018.csv\", dtype=str)\n",
    "\n",
    "# Filter domains with missing country_name\n",
    "missing = df[df['country_name'].isnull()][['domain', 'country_code', 'country_name']]\n",
    "\n",
    "# Print the result\n",
    "print(\"Domains with missing country_name and their country_code:\")\n",
    "print(missing.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71eac817-1292-4f87-b9c9-d8434c3095ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domains with missing country_name and their country_code:\n",
      "              domain country_code country_name\n",
      "   balkaninsight.com           RB          NaN\n",
      "       balkanist.net           RB          NaN\n",
      "      balkanrock.com           RB          NaN\n",
      "      glassrpske.com           RB          NaN\n",
      "learnserbianblog.com           RB          NaN\n",
      "       mcraeblog.com           RB          NaN\n",
      "       nezavisne.com           RB          NaN\n",
      "radiokontaktplus.org           RB          NaN\n",
      "             rtrs.tv           RB          NaN\n",
      "           rtvbn.com           RB          NaN\n",
      " stillinbelgrade.com           RB          NaN\n",
      "    streetart360.net           RB          NaN\n",
      "        svetplus.com           RB          NaN\n",
      "        urbanbug.net           RB          NaN\n",
      "       vukajlija.com           RB          NaN\n"
     ]
    }
   ],
   "source": [
    "rb = df[df[\"country_code\"] == \"RB\"][[\"domain\", \"country_code\", \"country_name\"]]\n",
    "\n",
    "# Print the result\n",
    "print(\"Domains with missing country_name and their country_code:\")\n",
    "print(rb.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7972a4ab-6850-4619-b4ac-cdb6966394b4",
   "metadata": {},
   "source": [
    "### Only 15 data is missing. Fortunately those data has country code. So, I am imputing corresponding country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d136fb41-a72e-4899-95ee-28d7c644dd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated RB entries:\n",
      "              domain country_code country_name\n",
      "   balkaninsight.com           RB       Serbia\n",
      "       balkanist.net           RB       Serbia\n",
      "      balkanrock.com           RB       Serbia\n",
      "      glassrpske.com           RB       Serbia\n",
      "learnserbianblog.com           RB       Serbia\n",
      "       mcraeblog.com           RB       Serbia\n",
      "       nezavisne.com           RB       Serbia\n",
      "radiokontaktplus.org           RB       Serbia\n",
      "             rtrs.tv           RB       Serbia\n",
      "           rtvbn.com           RB       Serbia\n",
      " stillinbelgrade.com           RB       Serbia\n",
      "    streetart360.net           RB       Serbia\n",
      "        svetplus.com           RB       Serbia\n",
      "        urbanbug.net           RB       Serbia\n",
      "       vukajlija.com           RB       Serbia\n",
      "\n",
      "Saved updated file to: MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018-updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original mapping CSV\n",
    "input_path = \"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018.csv\"\n",
    "df = pd.read_csv(input_path, dtype=str)\n",
    "\n",
    "# Fill in Serbia for all RB codes\n",
    "df.loc[df[\"country_code\"] == \"RB\", \"country_name\"] = \"Serbia\"\n",
    "\n",
    "# Save the updated CSV\n",
    "output_path = \"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018-updated.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Show a preview of the updated rows\n",
    "rb_updated = df[df[\"country_code\"] == \"RB\"][[\"domain\", \"country_code\", \"country_name\"]]\n",
    "print(\"Updated RB entries:\")\n",
    "print(rb_updated.to_string(index=False))\n",
    "\n",
    "# Inform user of saved file\n",
    "print(f\"\\nSaved updated file to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890beab-6f15-4631-bbba-0ea2acfbf73d",
   "metadata": {},
   "source": [
    "### Recheck the data to see if there any null value left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6de18e35-0165-4bd1-a3d9-43cb6715729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'domain': null_or_nan = 0, empty_string = 0\n",
      "'country_code': null_or_nan = 0, empty_string = 0\n",
      "'country_name': null_or_nan = 0, empty_string = 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018-updated.csv\", dtype=str)\n",
    "\n",
    "# Check each column\n",
    "for col in df.columns:\n",
    "    n_null   = df[col].isnull().sum()\n",
    "    n_empty  = (df[col] == \"\").sum()\n",
    "    print(f\"{col!r}: null_or_nan = {n_null}, empty_string = {n_empty}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5798f37c-acf4-4d31-81de-559ed4cfa5d6",
   "metadata": {},
   "source": [
    "## Join your news-country GDELT dataset with the example dataset to check the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dd90fbf-d035-4764-a8df-c52b85c757df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 100 news sites:\n",
      "\n",
      "                                    url         country              domain\n",
      "0                       https://cnn.com   United States             cnn.com\n",
      "1                     https://bbc.co.uk  United Kingdom           bbc.co.uk\n",
      "2                 https://bloomberg.com   United States       bloomberg.com\n",
      "3                   https://nytimes.com   United States         nytimes.com\n",
      "4            https://washingtonpost.com   United States  washingtonpost.com\n",
      "5               https://theguardian.com  United Kingdom     theguardian.com\n",
      "6                   https://foxnews.com   United States         foxnews.com\n",
      "7                   https://nbcnews.com   United States         nbcnews.com\n",
      "8                      https://cnbc.com   United States            cnbc.com\n",
      "9                   https://reuters.com  United Kingdom         reuters.com\n",
      "10                   https://forbes.com   United States          forbes.com\n",
      "11                 https://huffpost.com   United States        huffpost.com\n",
      "12                 https://politico.com   United States        politico.com\n",
      "13                      https://wsj.com   United States             wsj.com\n",
      "14                     https://time.com   United States            time.com\n",
      "15                 https://usatoday.com   United States        usatoday.com\n",
      "16              https://dailymail.co.uk  United Kingdom     dailymail.co.uk\n",
      "17               https://thetimes.co.uk  United Kingdom      thetimes.co.uk\n",
      "18                 https://thesun.co.uk  United Kingdom        thesun.co.uk\n",
      "19              https://telegraph.co.uk  United Kingdom     telegraph.co.uk\n",
      "20                 https://mirror.co.uk  United Kingdom        mirror.co.uk\n",
      "21                https://express.co.uk  United Kingdom       express.co.uk\n",
      "22            https://independent.co.uk  United Kingdom   independent.co.uk\n",
      "23                   https://nypost.com   United States          nypost.com\n",
      "24                  https://latimes.com   United States         latimes.com\n",
      "25                   https://usnews.com   United States          usnews.com\n",
      "26                    https://axios.com   United States           axios.com\n",
      "27             https://buzzfeednews.com   United States    buzzfeednews.com\n",
      "28                     https://vice.com   United States            vice.com\n",
      "29                https://aljazeera.com           Qatar       aljazeera.com\n",
      "30                 https://euronews.com          France        euronews.com\n",
      "31                   https://lemonde.fr          France          lemonde.fr\n",
      "32                   https://elpais.com           Spain          elpais.com\n",
      "33                   https://spiegel.de         Germany          spiegel.de\n",
      "34                  https://lefigaro.fr          France         lefigaro.fr\n",
      "35                  https://corriere.it           Italy         corriere.it\n",
      "36                https://repubblica.it           Italy       repubblica.it\n",
      "37           https://eluniversal.com.mx          Mexico  eluniversal.com.mx\n",
      "38              https://ouest-france.fr          France     ouest-france.fr\n",
      "39                    https://asahi.com           Japan           asahi.com\n",
      "40                     https://scmp.com       Hong Kong            scmp.com\n",
      "41            https://chinadaily.com.cn           China   chinadaily.com.cn\n",
      "42             https://straitstimes.com       Singapore    straitstimes.com\n",
      "43                 https://thehindu.com           India        thehindu.com\n",
      "44           https://hindustantimes.com           India  hindustantimes.com\n",
      "45  https://timesofindia.indiatimes.com           India      indiatimes.com\n",
      "46                     https://dawn.com        Pakistan            dawn.com\n",
      "47                 https://arabnews.com    Saudi Arabia        arabnews.com\n",
      "48           https://thejakartapost.com       Indonesia  thejakartapost.com\n",
      "49                       https://rt.com          Russia              rt.com\n",
      "\n",
      " merged data: \n",
      "\n",
      "                                    url         country              domain  \\\n",
      "0                       https://cnn.com   United States             cnn.com   \n",
      "1                     https://bbc.co.uk  United Kingdom           bbc.co.uk   \n",
      "2                 https://bloomberg.com   United States       bloomberg.com   \n",
      "3                   https://nytimes.com   United States         nytimes.com   \n",
      "4            https://washingtonpost.com   United States  washingtonpost.com   \n",
      "5               https://theguardian.com  United Kingdom     theguardian.com   \n",
      "6                   https://foxnews.com   United States         foxnews.com   \n",
      "7                   https://nbcnews.com   United States         nbcnews.com   \n",
      "8                      https://cnbc.com   United States            cnbc.com   \n",
      "9                   https://reuters.com  United Kingdom         reuters.com   \n",
      "10                   https://forbes.com   United States          forbes.com   \n",
      "11                 https://huffpost.com   United States        huffpost.com   \n",
      "12                 https://politico.com   United States        politico.com   \n",
      "13                      https://wsj.com   United States             wsj.com   \n",
      "14                     https://time.com   United States            time.com   \n",
      "15                 https://usatoday.com   United States        usatoday.com   \n",
      "16              https://dailymail.co.uk  United Kingdom     dailymail.co.uk   \n",
      "17               https://thetimes.co.uk  United Kingdom      thetimes.co.uk   \n",
      "18                 https://thesun.co.uk  United Kingdom        thesun.co.uk   \n",
      "19              https://telegraph.co.uk  United Kingdom     telegraph.co.uk   \n",
      "20                 https://mirror.co.uk  United Kingdom        mirror.co.uk   \n",
      "21                https://express.co.uk  United Kingdom       express.co.uk   \n",
      "22            https://independent.co.uk  United Kingdom   independent.co.uk   \n",
      "23                   https://nypost.com   United States          nypost.com   \n",
      "24                  https://latimes.com   United States         latimes.com   \n",
      "25                   https://usnews.com   United States          usnews.com   \n",
      "26                    https://axios.com   United States           axios.com   \n",
      "27             https://buzzfeednews.com   United States    buzzfeednews.com   \n",
      "28                     https://vice.com   United States            vice.com   \n",
      "29                https://aljazeera.com           Qatar       aljazeera.com   \n",
      "30                 https://euronews.com          France        euronews.com   \n",
      "31                   https://lemonde.fr          France          lemonde.fr   \n",
      "32                   https://elpais.com           Spain          elpais.com   \n",
      "33                   https://spiegel.de         Germany          spiegel.de   \n",
      "34                  https://lefigaro.fr          France         lefigaro.fr   \n",
      "35                  https://corriere.it           Italy         corriere.it   \n",
      "36                https://repubblica.it           Italy       repubblica.it   \n",
      "37           https://eluniversal.com.mx          Mexico  eluniversal.com.mx   \n",
      "38              https://ouest-france.fr          France     ouest-france.fr   \n",
      "39                    https://asahi.com           Japan           asahi.com   \n",
      "40                     https://scmp.com       Hong Kong            scmp.com   \n",
      "41            https://chinadaily.com.cn           China   chinadaily.com.cn   \n",
      "42             https://straitstimes.com       Singapore    straitstimes.com   \n",
      "43                 https://thehindu.com           India        thehindu.com   \n",
      "44           https://hindustantimes.com           India  hindustantimes.com   \n",
      "45  https://timesofindia.indiatimes.com           India      indiatimes.com   \n",
      "46                     https://dawn.com        Pakistan            dawn.com   \n",
      "47                 https://arabnews.com    Saudi Arabia        arabnews.com   \n",
      "48           https://thejakartapost.com       Indonesia  thejakartapost.com   \n",
      "49                       https://rt.com          Russia              rt.com   \n",
      "\n",
      "     gdelt_country  match  \n",
      "0    United States   True  \n",
      "1   United Kingdom   True  \n",
      "2    United States   True  \n",
      "3    United States   True  \n",
      "4    United States   True  \n",
      "5   United Kingdom   True  \n",
      "6    United States   True  \n",
      "7    United States   True  \n",
      "8    United States   True  \n",
      "9    United States  False  \n",
      "10   United States   True  \n",
      "11             NaN  False  \n",
      "12   United States   True  \n",
      "13   United States   True  \n",
      "14   United States   True  \n",
      "15   United States   True  \n",
      "16  United Kingdom   True  \n",
      "17  United Kingdom   True  \n",
      "18  United Kingdom   True  \n",
      "19  United Kingdom   True  \n",
      "20  United Kingdom   True  \n",
      "21  United Kingdom   True  \n",
      "22  United Kingdom   True  \n",
      "23   United States   True  \n",
      "24   United States   True  \n",
      "25   United States   True  \n",
      "26   United States   True  \n",
      "27             NaN  False  \n",
      "28   United States   True  \n",
      "29   United States  False  \n",
      "30   United States  False  \n",
      "31          France   True  \n",
      "32           Spain   True  \n",
      "33         Germany   True  \n",
      "34          France   True  \n",
      "35           Italy   True  \n",
      "36           Italy   True  \n",
      "37          Mexico   True  \n",
      "38          France   True  \n",
      "39           Japan   True  \n",
      "40           China  False  \n",
      "41           China   True  \n",
      "42       Singapore   True  \n",
      "43           India   True  \n",
      "44           India   True  \n",
      "45           India   True  \n",
      "46        Pakistan   True  \n",
      "47    Saudi Arabia   True  \n",
      "48       Indonesia   True  \n",
      "49          Russia   True  \n",
      "Overall GDELT‐vs-manual accuracy: 91.00%\n",
      "\n",
      "Mismatches:\n",
      "                        url              country gdelt_country\n",
      "        https://reuters.com       United Kingdom United States\n",
      "       https://huffpost.com        United States           NaN\n",
      "   https://buzzfeednews.com        United States           NaN\n",
      "      https://aljazeera.com                Qatar United States\n",
      "       https://euronews.com               France United States\n",
      "           https://scmp.com            Hong Kong         China\n",
      "      https://economist.com       United Kingdom United States\n",
      "https://thenationalnews.com United Arab Emirates           NaN\n",
      "           https://tass.com               Russia           NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tldextract\n",
    "\n",
    "# 1) Load your updated GDELT lookup table\n",
    "gdelt = pd.read_csv(\n",
    "    \"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018-updated.csv\",\n",
    "    dtype=str\n",
    ").rename(columns={\"country_name\":\"gdelt_country\"})\n",
    "\n",
    "\n",
    "# 3) Extract base-domain from each URL (e.g. \"bbc.co.uk\")\n",
    "def extract_domain(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return f\"{ext.domain}.{ext.suffix}\".lower()\n",
    "\n",
    "news_df[\"domain\"] = news_df[\"url\"].map(extract_domain)\n",
    "print(\"\\n Top 100 news sites:\\n\")\n",
    "print(news_df.head(50))\n",
    "\n",
    "gdelt[\"domain\"]   = gdelt[\"domain\"].str.lower()\n",
    "\n",
    "# 4) Merge to bring in the GDELT country\n",
    "merged = news_df.merge(\n",
    "    gdelt[[\"domain\",\"gdelt_country\"]],\n",
    "    on=\"domain\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 5) Flag where they agree\n",
    "merged[\"match\"] = merged[\"country\"] == merged[\"gdelt_country\"]\n",
    "print(\"\\n merged data: \\n\")\n",
    "print(merged.head(50))\n",
    "\n",
    "\n",
    "# 6) Calculate accuracy\n",
    "accuracy = merged[\"match\"].mean()\n",
    "print(f\"Overall GDELT‐vs-manual accuracy: {accuracy:.2%}\")\n",
    "\n",
    "#  (Optional) Inspect mismatches\n",
    "print(\"\\nMismatches:\")\n",
    "print(merged.loc[~merged[\"match\"], [\"url\",\"country\",\"gdelt_country\"]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2b6fd09-5e64-446d-9d64-92a8b19b46c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domains with missing country_name and their country_code:\n",
      "Empty DataFrame\n",
      "Columns: [domain, country_code, country_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "rb = df[df[\"domain\"] == \"buzzfeednews.com\"][[\"domain\", \"country_code\", \"country_name\"]]\n",
    "\n",
    "# Print the result\n",
    "print(\"Domains with missing country_name and their country_code:\")\n",
    "print(rb.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3d44a79-dec0-4ae3-aeaa-9d742efb5f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cnn.com': 'United States', 'bbc.co.uk': 'United Kingdom', 'bloomberg.com': 'United States', 'nytimes.com': 'United States', 'washingtonpost.com': 'United States', 'theguardian.com': 'United Kingdom', 'foxnews.com': 'United States', 'nbcnews.com': 'United States', 'cnbc.com': 'United States', 'reuters.com': 'United Kingdom', 'forbes.com': 'United States', 'huffpost.com': 'United States', 'politico.com': 'United States', 'wsj.com': 'United States', 'time.com': 'United States', 'usatoday.com': 'United States', 'dailymail.co.uk': 'United Kingdom', 'thetimes.co.uk': 'United Kingdom', 'thesun.co.uk': 'United Kingdom', 'telegraph.co.uk': 'United Kingdom', 'mirror.co.uk': 'United Kingdom', 'express.co.uk': 'United Kingdom', 'independent.co.uk': 'United Kingdom', 'nypost.com': 'United States', 'latimes.com': 'United States', 'usnews.com': 'United States', 'axios.com': 'United States', 'buzzfeednews.com': 'United States', 'vice.com': 'United States', 'aljazeera.com': 'Qatar', 'euronews.com': 'France', 'lemonde.fr': 'France', 'elpais.com': 'Spain', 'spiegel.de': 'Germany', 'lefigaro.fr': 'France', 'corriere.it': 'Italy', 'repubblica.it': 'Italy', 'eluniversal.com.mx': 'Mexico', 'ouest-france.fr': 'France', 'asahi.com': 'Japan', 'scmp.com': 'Hong Kong', 'chinadaily.com.cn': 'China', 'straitstimes.com': 'Singapore', 'thehindu.com': 'India', 'hindustantimes.com': 'India', 'indiatimes.com': 'India', 'dawn.com': 'Pakistan', 'arabnews.com': 'Saudi Arabia', 'thejakartapost.com': 'Indonesia', 'rt.com': 'Russia', 'thehill.com': 'United States', 'businessinsider.com': 'United States', 'chicagotribune.com': 'United States', 'theglobeandmail.com': 'Canada', 'cbc.ca': 'Canada', 'thestar.com': 'Canada', 'economist.com': 'United Kingdom', 'standard.co.uk': 'United Kingdom', 'metro.co.uk': 'United Kingdom', 'liberation.fr': 'France', 'lequipe.fr': 'France', 'france24.com': 'France', 'bild.de': 'Germany', 'dw.com': 'Germany', 'faz.net': 'Germany', 'elmundo.es': 'Spain', 'abc.es': 'Spain', 'lastampa.it': 'Italy', 'mainichi.jp': 'Japan', 'nikkei.com': 'Japan', 'yna.co.kr': 'South Korea', 'koreaherald.com': 'South Korea', 'smh.com.au': 'Australia', 'theaustralian.com.au': 'Australia', 'indianexpress.com': 'India', 'deccanherald.com': 'India', 'haaretz.com': 'Israel', 'thenationalnews.com': 'United Arab Emirates', 'gulfnews.com': 'United Arab Emirates', 'mg.co.za': 'South Africa', 'ahram.org.eg': 'Egypt', 'punchng.com': 'Nigeria', 'globo.com': 'Brazil', 'clarin.com': 'Argentina', 'elcomercio.pe': 'Peru', 'emol.com': 'Chile', 'nzz.ch': 'Switzerland', 'derstandard.at': 'Austria', 'wyborcza.pl': 'Poland', 'bangkokpost.com': 'Thailand', 'mb.com.ph': 'Philippines', 'thestar.com.my': 'Malaysia', 'cgtn.com': 'China', 'tass.com': 'Russia', 'aa.com.tr': 'Turkey', 'aftenposten.no': 'Norway', 'hs.fi': 'Finland', 'berlingske.dk': 'Denmark', 'kathimerini.gr': 'Greece', 'hurriyet.com.tr': 'Turkey'}\n",
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "18    False\n",
      "19    False\n",
      "Name: domain, dtype: bool\n",
      "New accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tldextract\n",
    "\n",
    "# 1) Load your “fixed‐RB” GDELT table\n",
    "gdelt = pd.read_csv(\"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018-updated.csv\", dtype=str)\n",
    "\n",
    "# 3) Extract base-domain on both tables\n",
    "def extract_domain(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return f\"{ext.domain}.{ext.suffix}\".lower()\n",
    "\n",
    "gdelt[\"domain\"]   = gdelt[\"domain\"].str.lower()  # if not already\n",
    "news_df[\"domain\"] = news_df[\"url\"].map(extract_domain)\n",
    "\n",
    "# 4) Build a correction map: domain → your manual country\n",
    "corrections = news_df.set_index(\"domain\")[\"country\"].to_dict()\n",
    "print(corrections)\n",
    "\n",
    "# 5) Overwrite GDELT’s country_name where you have a correction\n",
    "mask = gdelt[\"domain\"].isin(corrections)\n",
    "print(mask.head(20))\n",
    "gdelt.loc[mask, \"country_name\"] = gdelt.loc[mask, \"domain\"].map(corrections)\n",
    "\n",
    "# 6) (Optional) Re-compute your accuracy check to verify\n",
    "gdelt = gdelt.rename(columns={\"country_name\":\"gdelt_country\"})\n",
    "merged = news_df.merge(\n",
    "    gdelt[[\"domain\",\"gdelt_country\"]],\n",
    "    on=\"domain\", how=\"left\"\n",
    ")\n",
    "merged[\"match\"] = merged[\"country\"] == merged[\"gdelt_country\"]\n",
    "print(f\"New accuracy: {merged['match'].mean():.2%}\")\n",
    "\n",
    "# 7) Save out your newly “patched” GDELT table\n",
    "gdelt.to_csv(\"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018-patched.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "454c629a-e053-4468-ab0d-4af2eeea2cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved expanded + patched lookup to: MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018-expanded-patched.csv\n",
      "Final accuracy after patch: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tldextract\n",
    "import pycountry\n",
    "\n",
    "# ----- 1) Load your “RB-patched” GDELT lookup -----\n",
    "gdelt = pd.read_csv(\n",
    "    \"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018-updated.csv\",\n",
    "    dtype=str\n",
    ")\n",
    "\n",
    "\n",
    "# ----- 3) Extract “base domain” identically in both tables -----\n",
    "def extract_domain(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return f\"{ext.domain}.{ext.suffix}\".lower()\n",
    "\n",
    "news_df[\"domain\"] = news_df[\"url\"].map(extract_domain)\n",
    "gdelt[\"domain\"] = gdelt[\"domain\"].str.lower()\n",
    "\n",
    "# ----- 4) Append any domains missing from GDELT -----\n",
    "missing = set(news_df[\"domain\"]) - set(gdelt[\"domain\"])\n",
    "new_rows = []\n",
    "for dom in missing:\n",
    "    country = news_df.loc[news_df[\"domain\"] == dom, \"country\"].iat[0]\n",
    "    try:\n",
    "        code = pycountry.countries.lookup(country).alpha_2\n",
    "    except LookupError:\n",
    "        code = \"\"\n",
    "    new_rows.append({\n",
    "        \"domain\": dom,\n",
    "        \"country_code\": code,\n",
    "        \"country_name\": country\n",
    "    })\n",
    "\n",
    "if new_rows:\n",
    "    gdelt = pd.concat([gdelt, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "\n",
    "# ----- 5) Overwrite both country_name & country_code for all news_df domains -----\n",
    "# Build a domain→correct-country map\n",
    "corrections = news_df.set_index(\"domain\")[\"country\"].to_dict()\n",
    "\n",
    "# Overwrite country_name\n",
    "mask = gdelt[\"domain\"].isin(corrections)\n",
    "gdelt.loc[mask, \"country_name\"] = gdelt.loc[mask, \"domain\"].map(corrections)\n",
    "\n",
    "# Build domain→ISO2-code map and overwrite country_code\n",
    "code_map = {}\n",
    "for dom, country in corrections.items():\n",
    "    try:\n",
    "        code_map[dom] = pycountry.countries.lookup(country).alpha_2\n",
    "    except LookupError:\n",
    "        code_map[dom] = \"\"\n",
    "gdelt.loc[mask, \"country_code\"] = gdelt.loc[mask, \"domain\"].map(code_map)\n",
    "\n",
    "# ----- 6) Save the fully expanded + patched GDELT table -----\n",
    "output_csv = \"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018-expanded-patched.csv\"\n",
    "gdelt.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"Saved expanded + patched lookup to: {output_csv}\")\n",
    "\n",
    "# ----- 7) Merge & verify 100% accuracy -----\n",
    "merged = news_df.merge(\n",
    "    gdelt[[\"domain\",\"country_name\"]].rename(columns={\"country_name\":\"gdelt_country\"}),\n",
    "    on=\"domain\", how=\"left\"\n",
    ")\n",
    "merged[\"match\"] = merged[\"country\"] == merged[\"gdelt_country\"]\n",
    "accuracy = merged[\"match\"].mean()\n",
    "print(f\"Final accuracy after patch: {accuracy:.2%}\")\n",
    "\n",
    "# ----- 8) (Optional) Show any remaining mismatches (should be none) -----\n",
    "mismatches = merged.loc[~merged[\"match\"], [\"url\",\"country\",\"gdelt_country\"]]\n",
    "if not mismatches.empty:\n",
    "    print(\"Remaining mismatches:\")\n",
    "    print(mismatches.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2aa7f42-d50a-4281-bfe2-6c7d33a93dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             domain country_code country_name\n",
      "7684  aljazeera.com           QA        Qatar\n"
     ]
    }
   ],
   "source": [
    "gdelt = pd.read_csv(\n",
    "    \"MASTER-GDELTDOMAINSBYCOUNTRY-MAY2018-expanded-patched.csv\",\n",
    "    dtype=str\n",
    ")\n",
    "print( gdelt.loc[gdelt['domain'] == 'aljazeera.com'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a2052-608b-4b26-8812-2055cbd70820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42317db5-8528-4cba-9059-f16ff8e99c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4604a88-01a6-4fc5-b4e6-e07ac81361b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
